# Server Configuration
API_HOST=0.0.0.0
API_PORT=8096
ENVIRONMENT=development

# LLM Provider (openai, anthropic, or ollama)
LLM_PROVIDER=anthropic

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Default Model (fallback)
LLM_MODEL=gpt-4-turbo-preview
EMBEDDING_MODEL=text-embedding-3-small

# Database Connections
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password

QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=binelek_pipeline
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_postgres_password

# Service URLs
ONTOLOGY_SERVICE_URL=http://localhost:8091
PIPELINE_SERVICE_URL=http://localhost:8094
CONTEXT_SERVICE_URL=http://localhost:8095

# AI Configuration
MAX_REASONING_STEPS=5
TEMPERATURE=0.7
MAX_TOKENS=4000

# Tenant Isolation
ENABLE_TENANT_ISOLATION=true

# Logging
LOG_LEVEL=INFO
