# Service Configuration
SERVICE_NAME=binah-llm-extractor
SERVICE_VERSION=1.0.0
PORT=8110
LOG_LEVEL=INFO

# LLM Configuration
LLM_PROVIDER=openai  # openai, anthropic, or ollama
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=gpt-4  # or claude-3-5-sonnet-20241022 or llama3
LLM_TEMPERATURE=0.1

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_GROUP_ID=llm-entity-extractor
KAFKA_TOPIC_PATTERN=extraction.raw.*
KAFKA_AUTO_OFFSET_RESET=earliest
KAFKA_ENABLE_AUTO_COMMIT=true

# Service URLs
ONTOLOGY_SERVICE_URL=http://binah-ontology:8091
DISCOVERY_SERVICE_URL=http://binah-discovery:8106

# Confidence Thresholds
AUTO_APPLY_THRESHOLD=0.90
MANUAL_REVIEW_THRESHOLD=0.75

# Processing Configuration
BATCH_SIZE=10
MAX_RETRIES=3
REQUEST_TIMEOUT=30

# Feature Flags
ENABLE_BATCH_PROCESSING=true
ENABLE_RELATIONSHIP_EXTRACTION=true
SEND_TO_REVIEW_QUEUE=true
